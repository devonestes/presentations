---
layout: presentation
title: Going Multi-Node with ExUnit
permalink: /parallel_ex_unit/
---
layout: true
.watermark-left[@devoncestes]
.watermark-middle[ElixirConf EU 2021]

---
class: center, middle, headline

## Going Multi-Node
### with ExUnit

???
* This talk is one of my favorite kinds of talks.

---
class: center, middle

![](/assets/images/useful_cool_1.jpg)

???

---
class: center, middle

![](/assets/images/useful_cool_2.jpg)

???

---
class: center, middle

![](/assets/images/useful_cool_3.jpg)

???

---
class: center, middle

![](/assets/images/useful_cool_4.jpg)

???

---
class: center, middle

![](/assets/images/useful_cool_5.jpg)

???

---
class: center, middle

![](/assets/images/useful_cool_6.jpg)

???

---
class: center, middle

![](/assets/images/useful_cool_7.jpg)

???

---
class: center, middle

![](/assets/images/useful_cool_8.jpg)

???

---
class: center, middle

# Parallel ‚û°Ô∏è  Distributed

???

* There's a saying that when you have true parallelism, that you get distribution for free, and
we're going to see that in action today!
* So today we're going to talk about taking something that is already running in parallel, and how
to distribute that work across multiple nodes.
* But unlike most times this saying is used, we're going to use real-world code that almost all of
us have likely seen, and that's ExUnit.

---
class: center, middle

![](/assets/images/how_it_works.jpg)

???

* But before we can do that work, first we need to go over a bit about how ExUnit works, and
specifically how it runs our tests in parallel.

---
class: padding

.center[
# How it works
]

```
def run() do
  # ...
end

def loop(:async) do
  # ...
end

def loop(:sync) do
  # ...
end

def run_module(mod) do
  # ...
end

def run_test(test) do
  # ...
end
```

???

* This is a pretty high-level view of how ExUnit runs.
* We've got that main `run` function, which you'll see called in your `test_helper.exs` file.
* Then we've got these other functions, and we'll look a bit more at those in a second.

---
class: padding

.center[
# How it works
]

```
def run() do
  # Do some things
  loop(:async)
  # Do some other things and return results
end
```

???

* ExUnit does some setup of some other stuff that's not important for today, but the important
thing is when ExUnit starts, it enters that loop, first looking for `async` modules.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* This is a super simple version of that `loop` function.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case `wait_for_module(:async)` do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* Basically it's going to sit and wait for an async module to be ready to run.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case wait_for_module(:async) do
    `{:ok, mod}` ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* When it gets a message that a module is ready to run, it then spawns a process.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      `spawn(fn -> run_module(mod) end)`
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* And this process runs the tests in that module.
* This is important to note - the unit of paralleism in ExUnit is the module, not the test! Each
module can be run in parallel, but tests within that module are still run in series.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      `loop(:async)`

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* It then goes back into the loop once the process is spawned, waiting for another module to be
ready to run.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    `{:error, :no_more_async_modules}` ->
      loop(:sync)
  end
end
```

???
* Or when there are no more async modules to be run, it moves on and runs the modules that need to
be run in series.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      `loop(:sync)`
  end
end
```

???

* For today, we don't really care about that part. All the fun parallel stuff is basically done at
this point, and that's what we're going to try and distribute across multiple nodes.

---
class: center, middle, img-width-940

# Replace these images
![](/assets/images/ad1.png)

---
class: center, middle, img-width-940

# Replace these images
![](/assets/images/ad2.png)

---
class: center, middle, img-width-940

# Replace these images
![](/assets/images/ad3.png)

---
class: center, middle, img-width-940

# Replace these images
![](/assets/images/ad4.png)

---
class: center, middle, img-width-940

# Replace these images
![](/assets/images/ad5.png)

---
class: center, middle, img-width-940

# Replace these images
![](/assets/images/ad6.png)

---
class: center, middle, img-width-940

# Replace these images
![](/assets/images/ad7.png)

---
class: center, middle, img-width-940

# Replace these images
![](/assets/images/ad8.png)

---
class: center, middle

# Parallel ‚û°Ô∏è  Distributed

???

* Ok, so we've seen a bit about how it works in parallel, but now let's get to the meat of the
talk - running distributed!

---
class: center, middle

# `Node.spawn/2`
## &nbsp;

---
class: center, middle

# `Node.spawn/2`
## Thank you for coming to my TED talk

---
class: center, middle

![](/assets/images/draw_an_owl.jpg)

???

* It would be nice if it were that easy, but it's not! A lot of people talk about distribution in
this sort of way.
* "Just spawn a process on a different node - done!"
* But let's fill in some of those steps that are missing.

---
class: padding

.center[
# Our example tests
]

```
# test/my_test.exs

for letter <- ?A..?Z do













end
```

???

* Because we saw earlier that the unit of parallelism in ExUnit is the module, we'll need a bunch
of modules to run.
* We'll do some light metaprogramming for that!

---
class: padding

.center[
# Our example tests
]

```
# test/my_test.exs

for letter <- ?A..?Z do
  defmodule Module.concat([Example, Test, to_string([letter])]) do











  end
end
```

???

* Here's the extent of our metaprogramming, just letting us define 26 modules in a loop

---
class: padding

.center[
# Our example tests
]

```
# test/my_test.exs

for letter <- ?A..?Z do
  defmodule Module.concat([Example, Test, to_string([letter])]) do
    use ExUnit.Case, async: true

    test "calculates the fibonacci numbers" do
      for num <- 1..35 do
        assert fib(num) > 0
      end
    end

    defp fib(0) do 0 end
    defp fib(1) do 1 end
    defp fib(n) do fib(n-1) + fib(n-2) end
  end
end
```

???


---
class: padding

.center[
# In Series
]

```
$ mix test test/example_test.exs
..........................

Finished in 19.1 seconds (0.00s async, 19.1s sync)
26 tests, 0 failures
```

???

* If I run these tests on a slow computer I happened to have lying around, I see this

---
class: padding

.center[
# In Parallel
]

```
$ mix test test/example_test.exs
..........................

Finished in 7.2 seconds (7.2s async, 0.00s sync)
26 tests, 0 failures
```

???
* And I see this if I run them in parallel - 62% faster! This is nice, but we can do better.
* These are our starting benchmarks here that we're going to try and improve upon.

---
class: center, middle

# Monkey Patching ExUnit

???

* So the first thing we'll try is just monkey patching ExUnit and doing the simple thing I
mentioned above.
* A technique to add, modify, or suppress the default behavior of a piece of code at runtime
without changing its original source code.
* A lot of folks don't really know you can do this, but you can!

---
class: center, middle

# üòà

???

* This is generally a "bad thing" to do, though, so please don't actually try this in production
applications.

---
class: padding, middle

```bash
warning: redefining module ExUnit (current version loaded from
/home/devon/.asdf/installs/elixir/1.12.2-otp-23/bin/../lib/ex_unit/ebin/Elixir.ExUnit.beam)
  test/test_helper.exs:79
```

???

* When you do this, you'll see a message like this telling you you're redefining a module that's
already been defined.
* It does this because usually this is a mistake, not something you do on purpose
* What that message is saying is "Hey! You had already given me a module with that name to load into
the code server, but now you're giving me a new one!"
* How do we know to emit this message?

---
class: center, middle

# Code Server üíæ

???

* We know this because the BEAM (which is the VM that Elixir & Erlang applications run on) has a
thing called a Code Server.
* Let's try and understand this quickly before moving on.

---
class: center, middle

# Need images

???

You can think of the code server as a big key-value store, where keys are function names and
values are bytecode for functions. This part of the code server is called the `global export
table`.

---
class: padding, middle

```
iex(1)> fun = fn -> :ok end
#Function<45.40011524/0 in :erl_eval.expr/5>
```
???

Each function in our application has a name. This name is usually the MFA (module, function &
arity), but even private and anonymous functions actually have names in the BEAM code server.

---
class: center, middle

# Need images

???

For the most part (of course there are exceptions), the code server deals with modules. You can
load or unload a module from the code server, and the code server actually keeps _two_ versions of
a module around if you load a new one! This is how hot code loading works, by the way, and the
whole "keeping the current and previous version around" thing is so you can roll back if there's a
problem.

---
class: center, middle

# Need images

???

And in reality, the .beam files that Elixir (and other BEAM languages) emit are really just
instructions about how to populate this code server! That's why we get one .beam file for each
module.

---
class: center, middle

# Need images

???

So, we've got .beam files, and these .beam files populate the code server, and the code server
holds instructions for functions.

---
class: center, middle

# Need images

???

It's also _really_ important to note that every BEAM node gets its _OWN_ code server. You can't
share them across nodes. You _CAN_ however share .beam files across nodes.

---
class: center, middle

# Need images

???

When you boot a node, you can give it a path to a directory where .beam files are stored - this is
called (plainly enough) the `code path`. This `code path` can even be changed at runtime if you're
in interactive mode (there are two modes for a BEAM node).

So this code server is really, really important, and especially important to the task we're
undertaking today of trying to get ExUnit to run on multiple nodes.

Another thing to mention - Elixir also has its own code server! But that's really just used for
compilation, and so we're not going to cover that today. We'll be covering some stuff that's
private in Elixir & ExUnit, but the Elixir code server is super duper private, and so I just
wanted to make sure folks knew this existed so there's no confusion.

Ok, so now that we've got a bit of that learning about how ExUnit works, and how the code server
works, let's get back to the task at hand!

---
class: center, middle

# Monkey Patching ExUnit

???

So, here's the plan - since the unit of parallelism in ExUnit is the module, not the test, we're
going to try distributing this work by modules and not by individual tests. This means that module
A runs on machine 1, module B runs on machine 2, etc.

---
class: middle, padding

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* So if this is where the parallelism happens in ExUnit's runner, let's try and make it
distributed in the simplest possible way.

---
class: middle, padding

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      `node = Enum.random([Node.self() | Node.list()])`
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* First, let's get a node on which we can run this. For now we'll just do a random node from all
nodes in the cluster.
* And an extra special note for those of you playing along at home - in this specific case
`Enum.random` will actually always give us the same node and not a random one - but for now we're
going to pretend like it would so we can move faster!

---
class: middle, padding

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      node = Enum.random([Node.self() | Node.list()])
      `Node.spawn(node, fn -> run_module(mod) end)`
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* Node.spawn/2 just lets us spawn a process on a given node. You can think of Kernel.spawn/1 as
shorthand for this.

---
class: middle, padding

```
# test/test_helper.exs

defmodule ExUnit.Runner do
  # our new implementation
end

ExUnit.start()
```

???

And this is how we actually do our monkey patching! We re-define the module in our
`test_helper.exs` file, because that's loaded after we start our VM for the first time.

We need to remember that we're copying & pasting the WHOLE MODULE, and then making the changes
that we want to make.

---
class: center, middle

# üòû

???

* But sadly, this doesn't work...
* Why not? Well, remember that code server we spoke about just a few minutes ago???

---
class: padding, middle

```
1) Example.Test.A: failure on setup_all callback, all tests have been invalidated
     ** (UndefinedFunctionError) function Example.Test.A.__ex_unit__/2 is undefined or private.
     Did you mean one of:

           * __ex_unit__/0
           * __ex_unit__/2

     stacktrace:
       Example.Test.A.__ex_unit__(:setup_all, %{case: Example.Test.A, module: Example.Test.A})
```

???

* You'll actually get a spectacularly confusing error here!
* Usually this sort of thing in Elixir is considered a bug, but since we're _WAY_ off the beaten
path here and doing a lot of things we shouldn't be doing, I don't blame them for this.
* But I'll help you cut to the chase here - this is happening because of the two different code
servers!

---
class: center, middle

# Need picture

???

* Another cool thing about ExUnit - it has its own compiler!
* Our test modules are defined in .exs files, and that means they're not compiled by the standard
Elixir compiler.
* When we run `mix test`, it compiles and loads all our test files (based on the `_test.exs`
suffix) into the code server for the BEAM node that we've just started.
* It does a bunch of other stuff, too!
* So, we need to make sure that when we compile our actual test modules, that those get loaded
onto all the code servers in our cluster.

---
class: padding, middle

```
1) Example.Test.A: failure on setup_all callback, all tests have been invalidated
     ** (UndefinedFunctionError) function Example.Test.A.__ex_unit__/2 is undefined or private.
     Did you mean one of:

           * __ex_unit__/0
           * __ex_unit__/2

     stacktrace:
       Example.Test.A.__ex_unit__(:setup_all, %{case: Example.Test.A, module: Example.Test.A})
```

???

* So this specific error makes a bit more sense, right? When the error occured on Node 2, the
error was that the function was undefined or private. Basically, a function with that name wasn't
in the code server.
* But then when ExUnit formatted that error for us, it did that formatting on the main node which
_DID_ have that function in the code server, and it uses this information for the "Did you mean"
recommendation there.
* So, if we want to distribute this work, we've gotta load these modules into the code servers on
these other nodes.

---
class: middle, padding

```
path = :code.get_path()
:rpc.multicall(Node.list(), :code, :set_path, [path])

# or

{module, binary, filename} = :code.get_object_code(Example.Test.A)
:rpc.multicall(Node.list(), :code, :load_binary, [module, filename, binary])
```

???

* Now, normally if you want to load code into a code server, you can do that by
sharing the code path (remember, we can set that at runtime!).
* But for these .exs files, we don't actually write .beam files to disk, so that won't work!
* The other normal way you can load code into a code server is by giving the code server the info
it would normally find in the .beam file via a function call to `:code.load_binary/3`. This works
well for sure, but there's kind of another hitch.
* Normally when you do this, you would get the info for the code you want to load with
`:code.get_object_code/1`. But that doesn't actually pull the code from the code server - it pulls
it from the .beam files - and since we don't have .beam files for these test modules,
:code.get_object_code/1 errors!
* So, we've gotta make another change to how ExUnit works. Basically, we need to modify the ExUnit
compiler to look like this so we load all the test modules on all nodes.

---
class: padding, middle

```
case Kernel.ParallelCompiler.require(test_files, parallel_require_callbacks) do
  {:ok, _, _} -> :ok
  {:error, _, _} -> exit({:shutdown, 1})
end


# becomes


args = [test_files, parallel_require_callbacks]
{results, _} = :rpc.multicall(Kernel.ParallelCompiler, :require, args)

Enum.each(results, fn
  {:ok, _, _} -> :ok
  {:error, _, _} -> exit({:shutdown, 1})
end)
```

???

* With this change we'll now compile and load all the test files on all nodes instead of just the
one that was started when you ran `mix test`.
* Also funny to note - trying to compile Elixir files synchronously is actually surprisingly
difficult, so we're just not going to do that today.

---
class: center, middle

# üéâ

???

* And, woah - now it works! Kind of. Again, the simple version of this process I showed for
ExUnit's runner is a simplification, but the real change that we need to make isn't much more
complicated.

---
class: padding, middle

```
{test_module, invalid_tests, finished_tests} = run_module(config, test_module, to_run_tests)


# becomes


{test_module, invalid_tests, finished_tests} =
  :rpc.call(node, __MODULE__, :run_module, [config, test_module, to_run_tests])
```

???

* Not so bad, right?!
* There were a few other changes I made to this to make it work in my example, which is on GitHub
if you want to look through it and try it for yourself in a way that will show you the benefit
even if you just have a single machine (as long as it has at least 4 cores).

---
class: padding

.center[
# In Series
]

```
$ mix test test/example_test.exs
..........................

Finished in 19.1 seconds (0.00s async, 19.1s sync)
26 tests, 0 failures
```

???

* If I run these tests on a slow computer I happened to have lying around, I see this

---
class: padding

.center[
# In Parallel
]

```
$ mix test test/example_test.exs
..........................

Finished in 7.2 seconds (7.2s async, 0.00s sync)
26 tests, 0 failures
```

???
* And I see this if I run them in parallel - 62% faster! This is nice, but we can do better.
* These are our starting benchmarks here that we're going to try and improve upon.

---
class: padding

.center[
# Distributed
]

```
$ mix test test/example_test.exs
..........................

Finished in 3.7 seconds (3.7s async, 0.00s sync)
26 tests, 0 failures
```

???

* This was with me adding an extra 2 nodes, one with 2 cores and one with 4 cores
* 80% faster than in series
* 48% faster than parallel
* Given 26 cores and a bit of optimization, you could get this down to the time it take to
basically just run a single test, so probably around 1 second.

---
class: center, middle

![](/assets/images/useful_cool_8.jpg)

???

* So, you might be thinking to yourself right now "but Devon, this all seems really useful! We could
set up super-fast CI servers with a couple raspberry PIs that can run a long test suite super quick!

---
class: center, middle

![](/assets/images/draw_an_owl_circled.jpg)

???

* Yeah, if your application is dead simple, that can work. But most applications really aren't
designed to be run as part of a cluster. If yours is, then great! But it's a non-trivial amount of
work to make that happen, and the errors are really annoying and difficult to debug.

---
class: center, middle

# :code
# :rpc

???

* But, in our journey today we got to learn a bit about how ExUnit works and how the BEAM's code
server works. I think this is really fun stuff to know about, and I hope you agree!
* If your application literally has no state, or if your application is already set up for
distribution, then this could offer some benefit to you. But I'd wager a guess that 99% of folks
don't fit in one of those two buckets.
* So, I still think this is super cool because it shows us a lot of the power of the BEAM and some
of the really amazing things you can do (if you really need it), but because most people don't
need many of these things, it's not super useful to our everyday lives.
* Either way, I hope you learned something interesting and that you enjoyed the talk!
* Erlang gives us the really important stuff we need to make this work, so I'd really recommend
looking into some of the stuff in these modules. If you ever find yourself needing to draw the
rest of that owl, these two modules will likely have some answers for your questions.

---
class: center, middle

# Thank you! üáµüá±
