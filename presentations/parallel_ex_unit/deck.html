---
layout: presentation
title: Going Multi-Node with ExUnit
permalink: /parallel_ex_unit/
---
layout: true
.watermark-left[@devoncestes]
.watermark-middle[ElixirConf EU 2021]

---
class: center, middle, headline

## Going Multi-Node
### with ExUnit

???

* Super excited

---
class: center, middle, img-full

![I know the way!](/assets/images/i_know_the_way.gif)

???

---
class: center, middle

# Parallel ‚û°Ô∏è  Distributed

???

* There's a saying that when you have true parallelism, that you get distribution for free, and
we're going to see that in action today!
* So today we're going to talk about taking something that is already running in parallel, and how
to distribute that work across multiple nodes.
* But unlike most times this saying is used, we're going to use real-world code that almost all of
us have likely seen, and that's ExUnit.

---
class: center, middle

# What we won't cover
## &nbsp;
## &nbsp;

???

---
class: center, middle

# What we won't cover
## Creating/joining a cluster
## &nbsp;

???

---
class: center, middle

# What we won't cover
## Creating/joining a cluster
## Too much specific code

???

---
class: center, middle

# ü§î

???

* But before we can do that work, first we need to go over a bit about how ExUnit works, and
specifically how it runs our tests in parallel.

---
class: padding

.center[
# How it works
]

```
defmodule ExUnit.Runner do
  def run() do
    # ...
  end

  def loop(:async) do
    # ...
  end

  def loop(:sync) do
    # ...
  end

  def run_module(mod) do
    # ...
  end

  def run_test(test) do
    # ...
  end
end
```

???

* This is a pretty high-level view of how ExUnit runs.
* We've got that main `run` function, which you'll see called in your `test_helper.exs` file.
* Then we've got these other functions, and we'll look a bit more at those in a second.

---
class: padding

.center[
# How it works
]

```
def run() do
  # Do some things
  loop(:async)
  # Do some other things and return results
end
```

???

* ExUnit does some setup of some other stuff that's not important for today, but the important
thing is when ExUnit starts, it enters that loop, first looking for `async` modules.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* This is a super simple version of that `loop` function.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case `wait_for_module(:async)` do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* Basically it's going to sit and wait for an async module to be ready to run.
* It does this because our test files are compiled asynchronously and in parallel, so when one is
ready to run we get a message about that.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case wait_for_module(:async) do
    `{:ok, mod}` ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* When it gets a message that a module is ready to run, it then spawns a process.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      `spawn(fn -> run_module(mod) end)`
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* And this process runs the tests in that module.
* This is important to note - the unit of paralleism in ExUnit is the module, not the test! Each
module can be run in parallel, but tests within that module are still run in series even though
they're run in individual processes for isolation reasons.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      `loop(:async)`

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* It then goes back into the loop once the process is spawned, waiting for another module to be
ready to run.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    `{:error, :no_more_async_modules}` ->
      loop(:sync)
  end
end
```

???
* Or when there are no more async modules to be run, it moves on and runs the modules that need to
be run in series.

---
class: padding

.center[
# How it works
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      `loop(:sync)`
  end
end
```

???

* For today, we don't really care about that part. All the fun parallel stuff is basically done at
this point, and that's what we're going to try and distribute across multiple nodes.

---
class: center, middle, img-width-940

![](/assets/images/run1.jpg)

???

* So we can think of this one as our "main" process that represents that ExUnit runner

---
class: center, middle, img-width-940

![](/assets/images/run2.jpg)

???

* Then we have compilation of our test modules happening in another process

---
class: center, middle, img-width-940

![](/assets/images/run3.jpg)

???

* When a module is ready to run, a message is sent to our runner

---
class: center, middle, img-width-940

![](/assets/images/run4.jpg)

???

* And if the module is an async module, then our runner spawns another process that is in charge
of running the tests in that module

---
class: center, middle, img-width-940

![](/assets/images/run5.jpg)

???

* And this process keeps on going, of our ExUnit Runner spawning other processes per test module.

---
class: center, middle, img-width-940

![](/assets/images/run6.jpg)

???


---
class: center, middle, img-width-940

![](/assets/images/run7.jpg)

???


---
class: center, middle, img-width-940

![](/assets/images/run8.jpg)

???


---
class: center, middle, img-width-940

![](/assets/images/run9.jpg)

???


---
class: center, middle, img-width-940

![](/assets/images/run10.jpg)

???


---
class: center, middle, img-width-940

![](/assets/images/run11.jpg)

???

* Now normally, this all happens within the bounds of a single node
* A node here is defined as a single instance of the BEAM VM

---
class: center, middle, img-width-940

![](/assets/images/run12.jpg)

???

* But what we're going to do today is to try and change things so that just the compilation and
runner is happening on that "main" node

---
class: center, middle, img-width-940

![](/assets/images/run13.jpg)

???

* And then we can distribute the work of running the tests in each of these modules to their own
nodes

---
class: center, middle

# Parallel ‚û°Ô∏è  Distributed

???

* Ok, so we've seen a bit about how it works in parallel, but now let's get to the meat of the
talk - running distributed!

---
class: center, middle

## `spawn(fn -> run_module(module) end)`
## &nbsp;

---
class: center, middle

## ~~`spawn(fn -> run_module(module) end)`~~
## &nbsp;

---
class: center, middle

## `Node.spawn(node, fn -> run_module(module) end)`
## &nbsp;

---
class: center, middle

## `Node.spawn(node, fn -> run_module(module) end)`
## Thank you for coming to my TED talk

???

* It would be nice if it were that easy, but it's not! A lot of people talk about distribution in
this sort of way.
* "Just spawn a process on a different node - done!"
* But let's fill in some of those steps that are missing.

---
class: padding

.center[
# Our example tests
]

```
# test/my_test.exs

for letter <- ?A..?Z do













end
```

???

* Because we saw earlier that the unit of parallelism in ExUnit is the module, we'll need a bunch
of modules to run.
* We'll do some light metaprogramming for that!

---
class: padding

.center[
# Our example tests
]

```
# test/my_test.exs

for letter <- ?A..?Z do
  defmodule Module.concat([Example, Test, to_string([letter])]) do











  end
end
```

???

* Here's the extent of our metaprogramming, just letting us define 26 modules in a loop

---
class: padding

.center[
# Our example tests
]

```
# test/my_test.exs

for letter <- ?A..?Z do
  defmodule Module.concat([Example, Test, to_string([letter])]) do
    use ExUnit.Case, async: true










  end
end
```

???

---
class: padding

.center[
# Our example tests
]

```
# test/my_test.exs

for letter <- ?A..?Z do
  defmodule Module.concat([Example, Test, to_string([letter])]) do
    use ExUnit.Case, async: true

    test "calculates the fibonacci numbers" do



    end




  end
end
```

???

---
class: padding

.center[
# Our example tests
]

```
# test/my_test.exs

for letter <- ?A..?Z do
  defmodule Module.concat([Example, Test, to_string([letter])]) do
    use ExUnit.Case, async: true

    test "calculates the fibonacci numbers" do
      for num <- 1..35 do
        assert fib(num) > 0
      end
    end

    defp fib(0), do: 0
    defp fib(1), do: 1
    defp fib(n), do: fib(n-1) + fib(n-2)
  end
end
```

???


---
class: padding

.center[
# In Series
]

```
$ mix test test/example_test.exs
..........................

Finished in 19.1 seconds (0.00s async, 19.1s sync)
26 tests, 0 failures
```

???

* If I run these tests on a slow computer I happened to have lying around, I see this

---
class: padding

.center[
# In Parallel
]

```
$ mix test test/example_test.exs
..........................

Finished in 7.2 seconds (7.2s async, 0.00s sync)
26 tests, 0 failures
```

???
* And I see this if I run them in parallel - 62% faster! This is nice, but we can do better.
* These are our starting benchmarks here that we're going to try and improve upon.

---
class: center, middle

# Monkey Patching ExUnit üêí

???

* So the first thing we'll try is just monkey patching ExUnit and doing the simple thing I
mentioned above.
* A technique to add, modify, or suppress the default behavior of a piece of code at runtime
without changing its original source code.
* A lot of folks don't really know you can do this, but you can!

---
class: center, middle

# üòà

???

* This is generally a "bad thing" to do, though, so please don't actually try this in production
applications.

---
class: padding, middle

```bash
warning: redefining module ExUnit (current version loaded from
/home/devon/.asdf/installs/elixir/1.12.2-otp-23/bin/../lib/ex_unit/ebin/Elixir.ExUnit.beam)
  test/test_helper.exs:79
```

???

* When you do this, you'll see a message like this telling you you're redefining a module that's
already been defined.
* It does this because usually this is a mistake, not something you do on purpose
* What that message is saying is "Hey! You had already given me a module with that name to load into
the code server, but now you're giving me a new one!"
* How do we know to emit this message?

---
class: center, middle

# Code Server üíæ

???

* We know this because the BEAM (which is the VM that Elixir & Erlang applications run on) has a
thing called a Code Server.
* Let's try and understand this quickly before moving on.

---
class: center, middle

![](/assets/images/cs1.jpg)

???

You can think of the code server as a big key-value store, where keys are function names and
values are bytecode for functions. This part of the code server is called the `global export
table`.

---
class: center, middle

![](/assets/images/cs2.jpg)

???

For the most part (of course there are exceptions), the code server deals with modules. You can
load or unload a module from the code server, and the code server actually keeps _two_ versions of
a module around if you load a new one! This is how hot code loading works, by the way, and the
whole "keeping the current and previous version around" thing is so you can roll back if there's a
problem.

---
class: padding, middle

```
iex(1)> fun = fn -> :ok end
#Function<45.40011524/0 in :erl_eval.expr/5>
```
???

Each function in our application has a name. This name is usually the MFA (module, function &
arity), but even private and anonymous functions actually have names in the BEAM code server.

---
class: center, middle

![](/assets/images/cs3.jpg)

???

And in reality, the .beam files that Elixir (and other BEAM languages) emit are really just
instructions about how to populate this code server! That's why we get one .beam file for each
module.

---
class: center, middle

![](/assets/images/cs4.jpg)

???

So, we've got .beam files, and these .beam files populate the code server, and the code server
holds instructions for functions.

---
class: center, middle

![](/assets/images/cs5.jpg)

???

When you boot a node, you can give it one (or more) paths to directories where .beam files are
stored - this is called (plainly enough) the `code path`. This `code path` can even be changed at
runtime if you're in interactive mode (there are two modes for a BEAM node).

So this code server is really, really important, and especially important to the task we're
undertaking today of trying to get ExUnit to run on multiple nodes.

Another thing to mention - Elixir also has its own code server! But that's really just used for
compilation, and so we're not going to cover that today. We'll be covering some stuff that's
private in Elixir & ExUnit, but the Elixir code server is super duper private, and so I just
wanted to make sure folks knew this existed so there's no confusion.

Ok, so now that we've got a bit of that learning about how ExUnit works, and how the code server
works, let's get back to the task at hand!

---
class: center, middle

# Monkey Patching ExUnit üêí

???

So, here's the plan - since the unit of parallelism in ExUnit is the module, not the test, we're
going to try distributing this work by modules and not by individual tests. This means that module
A runs on machine 1, module B runs on machine 2, etc.

---
class: middle, padding

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* So if this is where the parallelism happens in ExUnit's runner, let's try and make it
distributed in the simplest possible way.

---
class: middle, padding

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      `node = Enum.random([Node.self() | Node.list()])`
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* First, let's get a node on which we can run this. For now we'll just do a random node from all
nodes in the cluster.
* And an extra special note for those of you playing along at home - in this specific case
`Enum.random` will actually always give us the same node and not a random one - but for now we're
going to pretend like it would so we can move faster!

---
class: middle, padding

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      node = Enum.random([Node.self() | Node.list()])
      `Node.spawn(node, fn -> run_module(mod) end)`
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* Node.spawn/2 just lets us spawn a process on a given node.
* So this is the change we'd like to make - how are we able to do that?

---
class: middle, padding

```
# test/test_helper.exs

defmodule ExUnit.Runner do
  # our new implementation
end

ExUnit.start()
```

???

And this is how we actually do our monkey patching! We re-define the module in our
`test_helper.exs` file, because that's loaded after we start our VM for the first time.

We need to remember that we're copying & pasting the WHOLE MODULE, and then making the changes
that we want to make.

---
class: center, middle

# üòû

???

* But sadly, this doesn't work...
* Why not? Well, remember that code server we spoke about just a few minutes ago???

---
class: padding, middle

```
1) Example.Test.A: failure on setup_all callback, all tests have been invalidated
     ** (UndefinedFunctionError) function Example.Test.A.__ex_unit__/2 is undefined or private.
     Did you mean one of:

           * __ex_unit__/0
           * __ex_unit__/2

     stacktrace:
       Example.Test.A.__ex_unit__(:setup_all, %{case: Example.Test.A, module: Example.Test.A})
```

???

* You'll actually get a spectacularly confusing error here!
* Usually this sort of thing in Elixir is considered a bug, but since we're _WAY_ off the beaten
path here and doing a lot of things we shouldn't be doing, I don't blame them for this.
* But I'll help you cut to the chase here - this is happening because of there are two different
code servers!

---
class: padding, middle

* Another cool thing about ExUnit - it has its own compiler!
* Our test modules are defined in .exs files, and that means they're not compiled by the standard
Elixir compiler.
* When we run `mix test`, it compiles and loads all our test files (based on the `_test.exs`
suffix) into the code server for the BEAM node that we've just started.
* It does a bunch of other stuff, too!

---
class: padding, middle

* So, we need to make sure that when we compile our actual test modules, that those get loaded
onto all the code servers in our cluster.
* So this specific error makes a bit more sense, right? When the error occured on Node 2, the
error was that the function was undefined or private. Basically, a function with that name wasn't
in the code server.
* But then when ExUnit formatted that error for us, it did that formatting on the main node which
_DID_ have that function in the code server, and it uses this information for the "Did you mean"
recommendation there.
* So, if we want to distribute this work, we have to also load these modules into the code servers
on these other nodes.

---
class: middle, padding

```
path = :code.get_path()



  
    
„ÄÄ ·öÄ‚ÄÉ
```

???

* Now, normally if you want to load code into a code server, you can do that by
sharing the code path.

---
class: middle, padding

```
path = :code.get_path()
:rpc.multicall(Node.list(), :code, :set_path, [path])





```

???


* Remember, we can set that at runtime!

---
class: middle, padding

```
path = :code.get_path()
:rpc.multicall(Node.list(), :code, :set_path, [path])

# or



```

???


* But for these .exs files, we don't actually write .beam files to disk, so that won't work!

---
class: middle, padding

```
path = :code.get_path()
:rpc.multicall(Node.list(), :code, :set_path, [path])

# or

{module, binary, filename} = :code.get_object_code(Example.Test.A)

```

???

* The other normal way you can load code into a code server is by giving the code server the info
it would normally find in the .beam file via a function call to `:code.load_binary/3`. This works
well for sure, but there's kind of another hitch.

---
class: middle, padding

```
path = :code.get_path()
:rpc.multicall(Node.list(), :code, :set_path, [path])

# or

{module, binary, filename} = :code.get_object_code(Example.Test.A)
:rpc.multicall(Node.list(), :code, :load_binary, [module, filename, binary])
```

???

* Normally when you do this, you would get the info for the code you want to load with
`:code.get_object_code/1`. But that doesn't actually pull the code from the code server - it pulls
it from the .beam files - and since we don't have .beam files for these test modules,
:code.get_object_code/1 errors!
* So, we've gotta make another change to how ExUnit works.
* One thing that we sort of skipped earlier is how ExUnit compiles these test modules.

---
class: padding, middle

```
case Kernel.ParallelCompiler.require(test_files, callbacks) do
  {:ok, _, _} -> :ok
  {:error, _, _} -> exit({:shutdown, 1})
end











```

???

* ExUnit actually has its own compiler that is uses to find & compile your test modules for you.

---
class: padding, middle

```
case Kernel.ParallelCompiler.require(test_files, callbacks) do
  {:ok, _, _} -> :ok
  {:error, _, _} -> exit({:shutdown, 1})
end


# becomes








```

???

* Basically, we need to modify this compiler so we load all the test modules on all nodes.

---
class: padding, middle

```
case Kernel.ParallelCompiler.require(test_files, callbacks) do
  {:ok, _, _} -> :ok
  {:error, _, _} -> exit({:shutdown, 1})
end


# becomes


{results, _} = :rpc.multicall(Kernel.ParallelCompiler, :require, [test_files, callbacks])

Enum.each(results, fn
  {:ok, _, _} -> :ok
  {:error, _, _} -> exit({:shutdown, 1})
end)
```

???

* With this change we'll now compile and load all the test files on all nodes instead of just the
one that was started when you ran `mix test`.
* This means that your cluster must be set up before you get to this point.

---
class: center, middle

# üéâ

???

* And, woah - now it works! Kind of. Again, the simple version of this process I showed for
ExUnit's runner is a simplification, but the real change that we need to make isn't much more
complicated.

---
class: padding, middle

```
{test_module, invalid_tests, finished_tests} = run_module(config, test_module, to_run_tests)


# becomes


{test_module, invalid_tests, finished_tests} =
  :rpc.call(node, __MODULE__, :run_module, [config, test_module, to_run_tests])
```

???

* Not so bad, right?!
* There were a few other changes I made to this to make it work in my example, which is on GitHub
if you want to look through it and try it for yourself in a way that will show you the benefit
even if you just have a single machine (as long as it has at least 4 cores).

---
class: padding

.center[
# In Series
]

```
$ mix test test/example_test.exs
..........................

Finished in 19.1 seconds (0.00s async, 19.1s sync)
26 tests, 0 failures
```

???

* If I run these tests on a slow computer I happened to have lying around, I see this

---
class: padding

.center[
# In Parallel
]

```
$ mix test test/example_test.exs
..........................

Finished in 7.2 seconds (7.2s async, 0.00s sync)
26 tests, 0 failures
```

???
* And I see this if I run them in parallel - 62% faster! This is nice, but we can do better.
* These are our starting benchmarks here that we're going to try and improve upon.

---
class: padding

.center[
# Distributed
]

```
$ mix test test/example_test.exs
..........................

Finished in 3.7 seconds (3.7s async, 0.00s sync)
26 tests, 0 failures
```

???

* This was with me adding an extra 2 nodes, one with 2 cores and one with 4 cores
* 80% faster than in series
* 48% faster than parallel
* Given 26 cores and a bit of optimization, you could get this down to the time it take to
basically just run a single test, so probably around 1 second.
* So, you might be thinking to yourself right now "this sounds great! We can set up super-fast CI
servers with a couple raspberry PIs that can run a long test suite super quick!"

---
class: center, middle

![](/assets/images/draw_an_owl.jpg)

???

* You may have seen this joke before about how to draw an owl. The idea is that by making the
beginning of it seem super easy that the whole process then looks easy when it's really quite
hard.

---
class: center, middle

![](/assets/images/draw_an_owl_circled.jpg)

???

* What we covered today was really just that first step in drawing an owl.
* If your Elixir applications store no state at all, or if the application is already designed to
be used in a cluster, then indeed this can work! But most applications really aren't designed to
be run as part of a cluster. If yours is, then great! But it's a non-trivial amount of work to
make that happen, and the errors are really annoying and difficult to debug.

---
class: center, middle

# :code
# :rpc

???

* But, in our journey today we got to learn a bit about how ExUnit works and how the BEAM's code
server works. I think this is really fun stuff to know about, and I hope you agree!
* If your application literally has no state, or if your application is already set up for
distribution, then this could offer some benefit to you. But I'd wager a guess that 99% of folks
don't fit in one of those two buckets.
* So, I still think this is super cool because it shows us a lot of the power of the BEAM and some
of the really amazing things you can do (if you really need it), but because most people don't
need many of these things, it's not super useful to our everyday lives.
* Either way, I hope you learned something interesting and that you enjoyed the talk!
* Erlang gives us the really important stuff we need to make this work, so I'd really recommend
looking into some of the stuff in these modules. If you ever find yourself needing to draw the
rest of that owl, these two modules will likely have some answers for your questions.

---
class: center, middle

# Thank you! üáµüá±
## https://github.com/devonestes/distributed_ex_unit
