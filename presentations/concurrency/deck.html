---
layout: presentation
title: Comparing Concurrency Patterns in Elixir and Erlang
permalink: /elixir_erlang_concurrency/
---
layout: true
.watermark-left[@devoncestes]
.watermark-middle[LambdaDays 2020]

---
class: center, middle, headline

## Comparing Common Concurrency Patterns
### in Elixir and Erlang

???
* Who here knows Erlang / Elixir?
* Process is an Actor.
* They communicate through message passing, and each process has an ordered inbox.
* Concurrency & Parallelism are great, but you need to know how to use them.
* People are thinking about these things.

---
class: center, middle

![](/assets/images/pattern_language.png)

???
* Paper first published in 1999.
* Patterns are great, because they give us shared vocabulary.
* This makes communication easier, and that's the hard part of programming.

---
class: center, middle

![](/assets/images/ppp.jpg)

???
* Published by Addison-Wesley in 2004
* Great acronym!

---
class: center, middle, headline

## <span class="red">C</span>omparing <span class="red">C</span>ommon <span class="red">C</span>oncurrency <span class="red">P</span>atterns
### in Elixir and Erlang

???

* I had kind of hoped there would be a really good acronym for the title for this talk.

---
class: center, middle

![](/assets/images/cccp_hockey.jpg)

???

* But then I remembered that this one was sort of taken already.

---
class: center, middle

![](/assets/images/PDSE-algorithm-structure.gif)

???

* The highlight (for me) from that original paper is this chart.
* It shows the basic layout of the patterns they identify and named.
* Now, because it's a 20 year old paper that was kind of hard to read, so I made this.

---
class: center, middle

![](/assets/images/photo_2020-01-12_15-11-03.jpg)

???

* Now we see that we start at the beginning, and there are decision points that help us get to our
final pattern.
* Usually patterns aren't prescriptions, but in this case they are!
* But not all of them are really _for_ us.
* 20 years ago - and really to an extent still today - most people thinking about this aren't
thiking at our scale.

---
class: center, middle

![](/assets/images/supercomptuer.jpg)

???

* A lot of the research on this is for people doing theoritical astrophysics simulations with
giant supercomputers trying to do as much vector math as they can.
* But that doesn't mean we can't still benefit from a bit of this!
* Even though we aren't (and shouldn't) just do what they do cause "it's what they do at Google."

---
class: center, middle

![](/assets/images/photo_2020-01-12_15-11-06.jpg)

---
class: center, middle

![](/assets/images/photo_2020-01-12_15-11-09.jpg)

---
class: center, middle

![](/assets/images/photo_2020-01-12_15-11-12.jpg)

---
class: center, middle

![](/assets/images/photo_2020-01-12_15-11-16.jpg)

---
class: center, middle

![](/assets/images/photo_2020-01-12_15-11-19.jpg)

---
class: center, middle

![](/assets/images/photo_2020-01-12_15-11-22.jpg)

---
class: center, middle

![](/assets/images/photo_2020-01-12_15-11-27.jpg)

---
class: center, middle

![](/assets/images/photo_2020-01-12_15-11-30.jpg)

???

* So today we're going to look at three examples from open source.
* We'll look at some code, and we'll also look at some pictures.

---
class: middle, padding

.cols[
.fifty[
.right[

# Benchee&nbsp;&nbsp;&nbsp;&nbsp;
# &nbsp;<br>&nbsp;
# &nbsp;<br>&nbsp;

]
]

.fifty[

# &nbsp;&nbsp;Reduction
# &nbsp;<br>&nbsp;
# &nbsp;<br>&nbsp;

]
]

---
class: middle, padding

.cols[
.fifty[
.right[

# Benchee&nbsp;&nbsp;&nbsp;&nbsp;
# ExUnit&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;
# &nbsp;<br>&nbsp;

]
]

.fifty[
.left[

# &nbsp;&nbsp;Reduction
# &nbsp;&nbsp;Asynchronous<br>&nbsp;&nbsp;Decomposition
# &nbsp;<br>&nbsp;

]
]
]

---
class: middle, padding

.cols[
.fifty[
.right[

# Benchee&nbsp;&nbsp;&nbsp;&nbsp;
# ExUnit&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;
# GenStage&nbsp;&nbsp;

]
]

.fifty[
.left[

# &nbsp;&nbsp;Reduction
# &nbsp;&nbsp;Asynchronous<br>&nbsp;&nbsp;Decomposition
# &nbsp;&nbsp;Pipeline<br>&nbsp;&nbsp;Processing

]
]
]

???

* So you may have noticed there were four green circles previously, but I only mentioned three
projects!
* Fourth one is so simple we can just cover it quickly.

---
class: center, middle, headline

## Embarrassingly Parallel

???

* Best name of them all!
* One example is sending emails.

---
class: padding

.center[
# Embarrassingly Parallel
]

```
def send_emails(emails) do # serial
  Enum.map(emails, fn email ->
    send_email(email)
  end)
end
```

???

* Here we map over the list of emails, sending them in series.

---
class: padding

.center[
# Embarrassingly Parallel
]

```
def send_emails(emails) do # serial
  Enum.map(emails, fn email ->
    send_email(email)
  end)
end

def send_emails(emails) do # parallel
  Enum.map(emails, fn email ->
    spawn(fn -> send_email(email) end)
  end)
end
```

???

* Making this paralell is as simple as spawning one process per email.

---
class: padding

.center[
# Embarrassingly Parallel
]

```
def send_emails(emails) do # serial
  Enum.map(emails, fn email ->
    send_email(email)
  end)
end

def send_emails(emails) do # parallel
  Enum.map(emails, fn email ->
    `spawn`(fn -> send_email(email) end)
  end)
end
```

???

* Now they all send in parallel - great!

---
class: center, middle, img-width-940

![](/assets/images/ep1.png)

???

---
class: center, middle, img-width-940

![](/assets/images/ep2.png)

???

---
class: center, middle, img-width-940

![](/assets/images/ep3.png)

???

---
class: center, middle, img-width-940

![](/assets/images/ep4.png)

???

---
class: center, middle, img-width-940

![](/assets/images/ep5.png)

???

---
class: center, middle, img-width-940

![](/assets/images/ep6.png)

???

---
class: center, middle, img-width-940

![](/assets/images/ep7.png)

???

---

class: padding

.center[
# Embarrassingly Parallel
]

- ## Eagerly evaluated, linear input

--

- ## No communication with parent

--

- ## No communication with siblings

--

- ## No shared dependencies between siblings

???

* Simplest, and probably one of the more common ones.
* But the most common one gives us just a little bit more.

---
class: center, middle, headline

## Reduction

???

* This one may be know by its other names - async/await & map/reduce.
* Quite a lot like Embarrassingly Parallel, but with one important difference.

---
class: padding

.center[
# Reduction
]

```
defmodule Parallel do
  def map(collection, func) do
    refs =
      Enum.map(collection, fn element ->
        Task.async(fn -> func.(element) end)
      end)

    Enum.map(refs, fn ref ->
      Task.await(ref, :infinity))
    end)
  end
end
```

???

* We map over our input, partitioning it in some fashion (one element per child process)
* Then reduce the output of that partitioned work back into a single result.

---
class: padding

.center[
# Reduction
]

```
defmodule Parallel do
  def map(collection, func) do
    refs =
      Enum.map(collection, fn element ->
        `Task.async`(fn -> func.(element) end)
      end)

    Enum.map(refs, fn ref ->
      `Task.await`(ref, :infinity))
    end)
  end
end

```

???

* We get a lot from the Task module
* I think it's important to go one level deeper here.

---

class: padding

.center[
# Basic async & await
]

```
def async(func) do
  ref = make_ref()
  me = self()
  spawn(fn -> send(me, {ref, func()}) end)
  ref
end
```

---

class: padding

.center[
# Basic async & await
]

```
def async(func) do
  ref = `make_ref()`
  me = self()
  spawn(fn -> send(me, {ref, func()}) end)
  ref
end
```

---

class: padding

.center[
# Basic async & await
]

```
def async(func) do
  ref = make_ref()
  `me` = self()
  spawn(fn -> send(me, {ref, func()}) end)
  ref
end
```

---

class: padding

.center[
# Basic async & await
]

```
def async(func) do
  ref = make_ref()
  me = self()
  `spawn(fn -> send(me, {ref, func()}) end)`
  ref
end
```

---

class: padding

.center[
# Basic async & await
]

```
def async(func) do
  ref = make_ref()
  me = self()
  spawn(fn -> send(me, {ref, func()}) end)
  `ref`
end
```

---

class: padding

.center[
# Basic async & await
]

```
def async(func) do
  ref = make_ref()
  me = self()
  spawn(fn -> send(me, {ref, func()}) end)
  ref
end
```

```
def await(ref, timeout \\ :infinity) do
  receive do
    {^ref, value} -> value
    after timeout -> {:error, :timeout}
  end
end
```

---

class: padding

.center[
# Basic async & await
]

```
def async(func) do
  ref = make_ref()
  me = self()
  spawn(fn -> send(me, {ref, func()}) end)
  ref
end
```

```
def await(ref, timeout \\ :infinity) do
  `receive` do
    {^ref, value} -> value
    after timeout -> {:error, :timeout}
  end
end
```

---

class: padding

.center[
# Basic async & await
]

```
def async(func) do
  ref = make_ref()
  me = self()
  spawn(fn -> send(me, {ref, func()}) end)
  ref
end
```

```
def await(ref, timeout \\ :infinity) do
  receive do
    {`^ref`, value} -> value
    after timeout -> {:error, :timeout}
  end
end
```

---

class: padding

.center[
# Basic async & await
]

```
def async(func) do
  ref = make_ref()
  me = self()
  spawn(fn -> send(me, {ref, func()}) end)
  ref
end
```

```
def await(ref, timeout \\ :infinity) do
  receive do
    {^ref, value} -> `value`
    after timeout -> {:error, :timeout}
  end
end
```

---

class: padding

.center[
# Basic async & await
]

```
def async(func) do
  ref = make_ref()
  me = self()
  spawn(fn -> send(me, {ref, func()}) end)
  ref
end
```

```
def await(ref, timeout \\ :infinity) do
  receive do
    {^ref, value} -> value
    `after timeout` -> {:error, :timeout}
  end
end
```

???

* Map in parallel, but reduction in series.
* Other ways to optimize, but this is generally ok.
* You could technically do this recursively for partitions of partitions.
* Let's look at an example to make it more clear.

---
class: padding

.hidden[
# _
]

```
me = self()

fun = fn seconds ->
  Process.sleep(seconds * 1000)    # Simulate some expensive work
  send(me, Time.utc_now().second)
end
```

--

```
Time.utc_now().second              #=> 48
```

--

```
Parallel.map([1, 2, 3, 1], fun)    #=> [49, 50, 51, 49]
```

--

```
Time.utc_now().second              #=> 51
```

???

* The computation is done in parallel, but reduce is done in series.
* And now in pictures!

---
class: center, middle, img-width-940

![](/assets/images/r1.png)

---
class: center, middle, img-width-940

![](/assets/images/r2.png)

---
class: center, middle, img-width-940

![](/assets/images/r3.png)

---
class: center, middle, img-width-940

![](/assets/images/r4.png)

---
class: center, middle, img-width-940

![](/assets/images/r5.png)

---
class: center, middle, img-width-940

![](/assets/images/r6.png)

---
class: center, middle, img-width-940

![](/assets/images/r7.png)

---

class: padding

.center[
# Basic async & await
]

```
def async(func) do
  ref = make_ref()
  me = self()
  spawn(fn -> send(me, {ref, func()}) end)
  ref
end

def await(ref, timeout \\ :infinity) do
  receive do
    {^ref, value} -> value
    after timeout -> {:error, :timeout}
  end
end
```

???

* Technically this is unrelated, but I think it's just so cool, I love to show it.
* Eat up all CPU on my machine - what about all machines?
* You may have heard someone say that with Actors, distribution is "free".

---
class: padding

.center[
# Distributed Async & Await
]

```
def async(func, `node \\ Node.self()`) do
  ref = make_ref()
  me = self()
  `Node.spawn(node`, fn -> send(me, {ref, func()}) end)
  ref
end

def await(ref, timeout) do
  receive do
    {^ref, value} -> value
    after timeout -> {:error, :timeout}
  end
end
```

???

* Yes, distribution is hard and full of gnarly edge cases, but this is really cool, right?

---
class: padding

.center[
# Reduction
]

- ## Eagerly evaluated, linear input

--

- ## Communication with parent allowed!

--

- ## No communication between children

--

- ## No shared dependencies between children

???

* What about when our input isn't eagerly evaluated?
* This is one where we have a huge advantage over the academics.

---
class: center, middle, headline

## Asynchronous Decomposition

???

* As you might imagine, dealing with data structures of unknown - and posssibly infinite! - size
is a real bummer in languages like C where you need to pre-allocate memory.
* For us it's not so bad, but I think it's still significant enough of a differnce to deserve its
own pattern.

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def run() do
  # ...
end

def loop(:async) do
  # ...
end

def loop(:sync) do
  # ...
end

def run_module(mod) do
  # ...
end

def run_test(test) do
  # ...
end
```

???

* On the face of it, you might think that this problem - run a bunch of tests in parallel - is
just another Reduction.
* In Elixir, test files aren't compiled - they're only compiled at run time.
* The process doing the partitioning (the parent) doesn't know exactly how much stuff it's going
to handle.

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def run() do
  EventManager.start()

  EventManager.suite_started()
  loop(:async)
  EventManager.suite_finished()

  results = EventManager.get_results()
  EventManger.stop()
  results
end
```

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```
---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case `wait_for_module(:async)` do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

???

* Here's where we have our asynchronous decomposition.

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case wait_for_module(:async) do
    `{:ok, mod}` ->
      spawn(fn -> run_module(mod) end)
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      `spawn(fn -> run_module(mod) end)`   # non-blocking
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)   # non-blocking
      `loop(:async)`

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end
```

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)   # non-blocking
      loop(:async)

    `{:error, :no_more_async_modules}` ->
      loop(:sync)
  end
end
```

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)   # non-blocking
      loop(:async)

    {:error, :no_more_async_modules} ->
      `loop(:sync)`
  end
end
```

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)   # non-blocking
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end

def loop(:sync) do
  case wait_for_module(:sync) do
    {:ok, mod} ->
      run_module(mod)
      loop(:sync)

    {:error, :no_more_modules} ->
      :ok
  end
end
```

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)   # non-blocking
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end

def loop(:sync) do
  case `wait_for_module(:sync)` do
    {:ok, mod} ->
      run_module(mod)
      loop(:sync)

    {:error, :no_more_modules} ->
      :ok
  end
end
```

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)   # non-blocking
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end

def loop(:sync) do
  case wait_for_module(:sync) do
    `{:ok, mod}` ->
      run_module(mod)
      loop(:sync)

    {:error, :no_more_modules} ->
      :ok
  end
end
```

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)   # non-blocking
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end

def loop(:sync) do
  case wait_for_module(:sync) do
    {:ok, mod} ->
      `run_module(mod)`                   # blocking
      loop(:sync)

    {:error, :no_more_modules} ->
      :ok
  end
end
```

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)   # non-blocking
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end

def loop(:sync) do
  case wait_for_module(:sync) do
    {:ok, mod} ->
      run_module(mod)                   # blocking
      `loop(:sync)`

    {:error, :no_more_modules} ->
      :ok
  end
end
```

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)   # non-blocking
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end

def loop(:sync) do
  case wait_for_module(:sync) do
    {:ok, mod} ->
      run_module(mod)                   # blocking
      loop(:sync)

    `{:error, :no_more_modules}` ->
      :ok
  end
end
```

---
class: padding

.center[
# Asynchronous Decomposition
]

```
def loop(:async) do
  case wait_for_module(:async) do
    {:ok, mod} ->
      spawn(fn -> run_module(mod) end)   # non-blocking
      loop(:async)

    {:error, :no_more_async_modules} ->
      loop(:sync)
  end
end

def loop(:sync) do
  case wait_for_module(:sync) do
    {:ok, mod} ->
      run_module(mod)                   # blocking
      loop(:sync)

    {:error, :no_more_modules} ->
      `:ok`
  end
end
```
---
class: padding

.center[
# Asynchronous Decomposition
]

```
def run_module(mod) do
  EventManager.module_started(mod)

  mod
  |> get_tests()
  |> Enum.map(&run_test/1)

  EventManager.module_finished(mod)
end
```
--
```
def run_test(test) do
  EventManager.test_started(test)
  result = run(test)
  EventManager.test_finished(result)
end
```

???

* This is all of course super simplified, but the gist of it I think is super interesting.

---
class: center, middle, img-width-940

![](/assets/images/ad1.png)

---
class: center, middle, img-width-940

![](/assets/images/ad2.png)

---
class: center, middle, img-width-940

![](/assets/images/ad3.png)

---
class: center, middle, img-width-940

![](/assets/images/ad4.png)

---
class: center, middle, img-width-940

![](/assets/images/ad5.png)

---
class: center, middle, img-width-940

![](/assets/images/ad6.png)

---
class: center, middle, img-width-940

![](/assets/images/ad7.png)

---
class: center, middle, img-width-940

![](/assets/images/ad8.png)

---
class: padding

.center[
# Asynchronous Decomposition
]

- ## Lazily evaluated input of unknown size

--

- ## Communication with parent allowed

--

- ## No communication between siblings

--

- ## No shared dependencies between siblings

???

* Trust me - if you run your tests in parallel with shared dependencies it's going to be a really
bummer.
* Dependencies are more than just what's in memory! Databases, file systems, third-party
dependencies, etc!
* Could we simplify this and use Reduction here instead?

---
class: padding

.center[
# ExUnit As Reduction
]

```
def run() do
  {sync_modules, async_modules} = load_modules()

  results =
    Parallel.map(async_modules, &run_module/1) ++
      Enum.map(sync_modules, &run_module/1)

  format_results(results)
end
```

???

* Yeah, sure, kind of! It would be slower, but it would indeed work.
* The big difference here again is just the input - eagerly or lazily evaluated.
* Again, this is a much bigger difference when you're working in C or something, but it's still
important for clear communication.

---
class: padding, center, headline, middle

## Pipeline Processing

???

* The other great thing about Asynchronous Decomposition is how it serves as a sort of middle
groud to this next pattern.
* This is what it sounds like. You may have heard of or seen other examples of this in the past.
* The thing is, doing this _right_ is actually quite hard, and so if you need to reach for this,
you really don't want to write your own.

---
class: center, middle, img-width-940

![](/assets/images/pp1.png)

---
class: center, middle, img-width-940

![](/assets/images/pp2.png)

---
class: center, middle, img-width-940

![](/assets/images/pp3.png)

---
class: center, middle, img-width-940

![](/assets/images/pp4.png)

---
class: center, middle, img-width-940

![](/assets/images/pp5.png)

---
class: center, middle, img-width-940

![](/assets/images/pp6.png)

---
class: center, middle, img-width-940

![](/assets/images/pp7.png)

---
class: center, middle, img-width-940

![](/assets/images/pp8.png)

---
class: center, middle, img-width-940

![](/assets/images/pp9.png)

---
class: center, middle, img-width-940

![](/assets/images/pp10.png)

---
class: center, middle, img-width-940

![](/assets/images/pp11.png)

---
class: padding

.center[
# Pipeline processing
]

- ## Lazily evaluated collection of unknown size

--

- ## Communication with parent allowed (rare)

--

- ## Dependencies between sibilings allowed

--

- ## Shared dependencies allowed (but require management)

---
class: center, middle, headline

## Summary

|                                        | Input evaluation      | Communication<br>w/ parent  | Communication<br>w/ siblings  | Shared dependencies  |
|----------------------------------------|-----------------------|-----------------------------|-----------------------------------------|----------------------|
| <h5>Embarrassingly<br>Parallel</h5>    | Eager                 | No                          | No                                      | No                   |
| <h5>&nbsp;</h5>   |          &nbsp;     |    &nbsp;                 |       &nbsp;               |    &nbsp;            |
| <h5>&nbsp;<br>&nbsp;</h5>   |          &nbsp;     |    &nbsp;                 |       &nbsp;               |    &nbsp;            |
| <h5>&nbsp;<br>&nbsp;</h5>   |          &nbsp;     |    &nbsp;                 |       &nbsp;               |    &nbsp;            |

???

* We've seen the four big ones, let's just go over one more time the characteristics of each of
them.

---
class: center, middle, headline

## Summary

|                                        | Input evaluation      | Communication<br>w/ parent  | Communication<br>w/ siblings  | Shared dependencies  |
|----------------------------------------|-----------------------|-----------------------------|-----------------------------------------|----------------------|
| <h5>Embarrassingly<br>Parallel</h5>    | Eager                 | No                          | No                                      | No                   |
| <h5>Reduction</h5>                     | Eager                 | Yes                         | No                                      | No                   |
| <h5>&nbsp;<br>&nbsp;</h5>   |          &nbsp;     |    &nbsp;                 |       &nbsp;               |    &nbsp;            |
| <h5>&nbsp;<br>&nbsp;</h5>   |          &nbsp;     |    &nbsp;                 |       &nbsp;               |    &nbsp;            |

---
class: center, middle, headline

## Summary

|                                        | Input evaluation      | Communication<br>w/ parent  | Communication<br>w/ siblings  | Shared dependencies  |
|----------------------------------------|-----------------------|-----------------------------|-----------------------------------------|----------------------|
| <h5>Embarrassingly<br>Parallel</h5>    | Eager                 | No                          | No                                      | No                   |
| <h5>Reduction</h5>                     | Eager                 | Yes                         | No                                      | No                   |
| <h5>Asynchronous<br>Decomposition</h5> | Lazy                  | Yes                         | No                                      | No                   |
| <h5>&nbsp;<br>&nbsp;</h5>   |          &nbsp;     |    &nbsp;                 |       &nbsp;               |    &nbsp;            |
---
class: center, middle, headline

## Summary

|                                        | Input evaluation      | Communication<br>w/ parent  | Communication<br>w/ siblings  | Shared dependencies  |
|----------------------------------------|-----------------------|-----------------------------|-----------------------------------------|----------------------|
| <h5>Embarrassingly<br>Parallel</h5>    | Eager                 | No                          | No                                      | No                   |
| <h5>Reduction</h5>                     | Eager                 | Yes                         | No                                      | No                   |
| <h5>Asynchronous<br>Decomposition</h5> | Lazy                  | Yes                         | No                                      | No                   |
| <h5>Pipeline<br>Processing</h5>        | Lazy                  | Yes                         | Yes                                     | Yes                  |

---
class: center, middle

![](/assets/images/sketch_logo.png)

???

* Big thank you to Sketch for supporting me in speaking here today.
* We are indeed hiring for Elixir positions, so if you're curious about what we're doing there
come and chat!

---
class: center, middle, headline

# Thank you! ðŸ‡µðŸ‡±
